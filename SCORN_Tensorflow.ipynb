{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d874cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import random\n",
    "from random import randint\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from scipy.io import loadmat\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Activation, MaxPooling2D, Dropout, Conv2D,AveragePooling2D\n",
    "from keras.layers.normalization.batch_normalization_v1 import BatchNormalization\n",
    "from keras.optimizers import gradient_descent_v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d937f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 1, 1, 12)          24        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 1, 12)          0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 1, 12)         0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 1, 12)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 12)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate model for predictor\"\"\"\n",
    "model=Sequential()\n",
    "input_dim=(1,1,1)\n",
    "\n",
    "#1\n",
    "model.add(Conv2D(filters=12,\n",
    "                 kernel_size=(1,1),\n",
    "                 strides=(1,1),\n",
    "                 padding='valid',\n",
    "                 input_shape=input_dim) )   #conv\n",
    "\n",
    "model.add(Activation('relu'))     #Relu\n",
    "#model.add(BatchNormalization())     #BN\n",
    "model.add(AveragePooling2D(pool_size = ( 1,1), strides=(2,2)))  #AP\n",
    "#model.add(BatchNormalization())                   #BN（CNN）\n",
    "model.add(MaxPooling2D(pool_size = ( 1, 1 ), strides=(2,2)))  #MP\n",
    "\n",
    "#2\n",
    "#model.add(Conv2D(filters=25,\n",
    "#                 kernel_size=(1,1),\n",
    "#                 strides=(1,1),\n",
    "#                 padding='valid',\n",
    "#                 input_shape=input_dim))  \n",
    "#model.add(BatchNormalization())  \n",
    "\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(12))\n",
    "#model.add(Activation('relu')) \n",
    "model.add(Dense(9,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d73789",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0005\n",
    "opt = gradient_descent_v2.SGD(learning_rate=lr)\n",
    "model.compile(optimizer=opt ,loss='mean_squared_error')\n",
    "#data = loadmat(\"dataXY.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7b763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6242, 10)\n",
      "(4994, 1, 1, 1)\n",
      "(4994, 9)\n",
      "(1248, 1, 1, 1)\n",
      "(1248, 9)\n"
     ]
    }
   ],
   "source": [
    "#Data Loading\n",
    "data = pd.read_csv(\"SCORNdata.csv\",header=None)\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "## validation\n",
    "D=data.to_numpy();\n",
    "k=5;\n",
    "np.random.shuffle(D)\n",
    "dataset = np.array_split(D, k)\n",
    "train_set = dataset.copy()\n",
    "test_set = train_set.pop(3)\n",
    "train_set = np.vstack(train_set)\n",
    "train_set=np.array(train_set)\n",
    "test_set=np.array(test_set)\n",
    "trainX=train_set[:,9:10]\n",
    "#print(trainX.shape)\n",
    "trainY=train_set[:,0:9]\n",
    "#print(trainY.shape)\n",
    "testX=test_set[:,9:10]\n",
    "#print(testX.shape)\n",
    "testY=test_set[:,0:9]\n",
    "#print(testY.shape)\n",
    "\n",
    "trainX =trainX.reshape((trainX.shape[0], 1, 1,1))\n",
    "testX =testX.reshape((testX.shape[0],testX.shape[1], 1,1))\n",
    "print(trainX.shape )\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e044c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4994/4994 [==============================] - 21s 2ms/step - loss: 1219.2390\n",
      "Epoch 2/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 288.7888\n",
      "Epoch 3/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 95.3495\n",
      "Epoch 4/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 31.5888\n",
      "Epoch 5/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 10.5706\n",
      "Epoch 6/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 3.6420\n",
      "Epoch 7/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 1.3582\n",
      "Epoch 8/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.6058\n",
      "Epoch 9/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.3577\n",
      "Epoch 10/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2760\n",
      "Epoch 11/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2490\n",
      "Epoch 12/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2401\n",
      "Epoch 13/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2372\n",
      "Epoch 14/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2363\n",
      "Epoch 15/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2359\n",
      "Epoch 16/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 17/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 18/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 19/100\n",
      "4994/4994 [==============================] - 12s 2ms/step - loss: 0.2358\n",
      "Epoch 20/100\n",
      "4994/4994 [==============================] - 13s 3ms/step - loss: 0.2358\n",
      "Epoch 21/100\n",
      "4994/4994 [==============================] - 12s 2ms/step - loss: 0.2358\n",
      "Epoch 22/100\n",
      "4994/4994 [==============================] - 13s 3ms/step - loss: 0.2358\n",
      "Epoch 23/100\n",
      "4994/4994 [==============================] - 13s 3ms/step - loss: 0.2358\n",
      "Epoch 24/100\n",
      "4994/4994 [==============================] - 13s 3ms/step - loss: 0.2358\n",
      "Epoch 25/100\n",
      "4994/4994 [==============================] - 12s 3ms/step - loss: 0.2358\n",
      "Epoch 26/100\n",
      "4994/4994 [==============================] - 12s 2ms/step - loss: 0.2358\n",
      "Epoch 27/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 28/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 29/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 30/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 31/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 32/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 33/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 34/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 35/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 36/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2358\n",
      "Epoch 37/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 38/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 39/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 40/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2358\n",
      "Epoch 41/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 42/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 43/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 44/100\n",
      "4994/4994 [==============================] - 13s 3ms/step - loss: 0.2358\n",
      "Epoch 45/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 46/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 47/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 48/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 49/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 50/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 51/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 52/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 53/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 54/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2358\n",
      "Epoch 55/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 56/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2358\n",
      "Epoch 57/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 58/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 59/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 60/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 61/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 62/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 63/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 64/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 65/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 66/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 67/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 68/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 69/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 70/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 71/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 72/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 73/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 74/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 75/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 76/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 77/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 78/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 79/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 80/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 81/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 82/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 83/100\n",
      "4994/4994 [==============================] - 8s 2ms/step - loss: 0.2358\n",
      "Epoch 84/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2358\n",
      "Epoch 85/100\n",
      "4994/4994 [==============================] - 8s 2ms/step - loss: 0.2358\n",
      "Epoch 86/100\n",
      "4994/4994 [==============================] - 9s 2ms/step - loss: 0.2358\n",
      "Epoch 87/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 88/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 89/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 90/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 91/100\n",
      "4994/4994 [==============================] - 10s 2ms/step - loss: 0.2358\n",
      "Epoch 92/100\n",
      "4994/4994 [==============================] - 12s 2ms/step - loss: 0.2358\n",
      "Epoch 93/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 94/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 95/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 97/100\n",
      "4994/4994 [==============================] - 12s 2ms/step - loss: 0.2358\n",
      "Epoch 98/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n",
      "Epoch 99/100\n",
      "4994/4994 [==============================] - 12s 2ms/step - loss: 0.2358\n",
      "Epoch 100/100\n",
      "4994/4994 [==============================] - 11s 2ms/step - loss: 0.2358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e3b5037c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY,epochs=100, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609f954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48707994972185537\n",
      "0.33426430450900974\n",
      "0.9997693617443713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error # MSE\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import r2_score # R square\n",
    "from math import sqrt\n",
    "y_1=model.predict(testX)\n",
    "yhatt=y_1\n",
    "Rmse=sqrt(mean_squared_error(testY,yhatt))\n",
    "mae=mean_absolute_error(testY,yhatt)\n",
    "R2=r2_score (testY.T,yhatt.T)\n",
    "print(Rmse)\n",
    "print(mae)\n",
    "print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3206952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
